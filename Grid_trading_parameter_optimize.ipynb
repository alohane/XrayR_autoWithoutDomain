{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b6e736-7e8c-4cf9-93a1-b2b498fce2b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from hftbacktest import NONE, NEW, HftBacktest, GTX, FeedLatency, BUY, SELL, Linear, Stat\n",
    "from numba import njit\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6581a4eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "              # pd.read_pickle('CollectData/data/btcusdt_20230228.pkl', compression='gzip'),\n",
    "              pd.read_pickle('CollectData/data/btcusdt_20230227.pkl', compression='gzip')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8711633",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[df.index < 1000]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec3c0477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, validate, test = np.split(df, [int(.6*len(df)), int(.8*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e990ed40-09a6-44d7-8061-85b03760f81d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Support And Resistance\n",
    "\n",
    "\n",
    "def leftLimitExtract(bids,leftLimit):\n",
    "  res = []   \n",
    "  for x in bids:\n",
    "    # num1 = float(x)\n",
    "    num1 = x\n",
    "    if num1< leftLimit:\n",
    "      break\n",
    "    num2 = float(bids[x])\n",
    "    # num2 = bids[x]\n",
    "    res.append([num1,num2])\n",
    "  return res\n",
    "\n",
    "\n",
    "def rightLimitExtract(asks,rightLimit):\n",
    "  # print(asks)\n",
    "  res = []\n",
    "  for x in asks:\n",
    "    # num1 = float(x)\n",
    "    num1 = x\n",
    "    if num1 > rightLimit:\n",
    "      break\n",
    "    num2 = float(asks[x])\n",
    "    # print(x)\n",
    "    # num2 = asks[x]\n",
    "    res.append([num1,num2])\n",
    "  return res\n",
    "\n",
    "def limitExtractDepth(bids,asks,limitPercent):\n",
    "\n",
    "  currBidPrice = float(next(iter(bids)))\n",
    "  leftLimit = currBidPrice - (currBidPrice*limitPercent)\n",
    "  currAskPrice = float(next(iter(asks)))\n",
    "  rightLimit = currAskPrice + (currAskPrice*limitPercent)\n",
    "  bids = leftLimitExtract(bids,leftLimit)\n",
    "  asks = rightLimitExtract(asks,rightLimit)\n",
    "  return bids,asks\n",
    "\n",
    "\n",
    "\n",
    "# @njit\n",
    "# def histogram(data, weights, bins):\n",
    "#     # Compute the range of the data\n",
    "#     data_range = np.max(data) - np.min(data)\n",
    "    \n",
    "#     # Compute the width of each bin\n",
    "#     bin_width = data_range / bins \n",
    "\n",
    "        \n",
    "    \n",
    "#     # Initialize the histogram counts\n",
    "#     counts = np.zeros(bins, dtype=np.float64)\n",
    "    \n",
    "#     # Loop over the data points and accumulate the counts\n",
    "#     for i in range(len(data)):\n",
    "#         # Compute the bin index for this data point\n",
    "#         bin_index = int((data[i] - np.min(data)) // bin_width)\n",
    "        \n",
    "#         # Add the weight of this data point to the appropriate bin\n",
    "#         counts[bin_index] += weights[i]\n",
    "    \n",
    "#     # Compute the bin edges\n",
    "#     bin_edges = np.linspace(np.min(data), np.max(data), bins+1)\n",
    "    \n",
    "#     return counts, bin_edges\n",
    "\n",
    "def histogram(data, weights, bins):\n",
    "    # Compute the range of the data\n",
    "    data_range = np.max(data) - np.min(data)\n",
    "    \n",
    "    # Compute the width of each bin\n",
    "    bin_width = data_range / bins \n",
    "    \n",
    "    # Initialize the histogram counts\n",
    "    counts = np.zeros(bins, dtype=np.float64)\n",
    "    \n",
    "    # Check if bin_width is 0\n",
    "    if bin_width == 0:\n",
    "        # Handle the case when bin_width is 0\n",
    "        # For example, return an empty histogram\n",
    "        return counts, np.array([np.min(data), np.max(data)])\n",
    "    \n",
    "    # Loop over the data points and accumulate the counts\n",
    "    for i in range(len(data)):\n",
    "        # Compute the bin index for this data point\n",
    "        bin_index = int((data[i] - np.min(data)) // bin_width)\n",
    "        \n",
    "        # Add the weight of this data point to the appropriate bin\n",
    "        counts[bin_index] += weights[i]\n",
    "    \n",
    "    # Compute the bin edges\n",
    "    bin_edges = np.linspace(np.min(data), np.max(data), bins+1)\n",
    "    \n",
    "    return counts, bin_edges\n",
    "\n",
    "\n",
    "def getSupportResistance(bids, asks, limitPercent):\n",
    "    lineNumber = 5\n",
    "    binNum=50   \n",
    "    \n",
    "    support = []    \n",
    "    if bids:\n",
    "        arr_bids = np.array(bids) \n",
    "        x_bids, y_bids = histogram(arr_bids[:, 0],arr_bids[:, 1], binNum)\n",
    "        y_bids = [(y_bids[i] + y_bids[i-1])/2 for i in range(1, len(y_bids))]\n",
    "        y_bids = np.asarray(y_bids, dtype=np.float64)\n",
    "        x_bids = np.asarray(x_bids, dtype=np.float64)\n",
    "\n",
    "        for i in range(y_bids.shape[0]):\n",
    "            row = []\n",
    "            row.append(y_bids[i])\n",
    "            row.append(x_bids[i])\n",
    "            support.append(row)\n",
    "        support.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    resistance = []\n",
    "    if asks:\n",
    "        arr_asks = np.array(asks) \n",
    "        x_asks, y_asks = histogram(arr_asks[:, 0],arr_asks[:, 1], binNum)  \n",
    "        y_asks = [(y_asks[i] + y_asks[i-1])/2 for i in range(1, len(y_asks))]\n",
    "        y_asks = np.asarray(y_asks, dtype=np.float64)\n",
    "        x_asks = np.asarray(x_asks, dtype=np.float64)\n",
    "        for i in range(y_asks.shape[0]):\n",
    "            row = []\n",
    "            row.append(y_asks[i])\n",
    "            row.append(x_asks[i])\n",
    "            resistance.append(row)\n",
    "        resistance.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # print(resistance)\n",
    "    return support[:lineNumber], resistance[:lineNumber]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf6cfcde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def predict_njit(half_spread, lineNumber, skew, X, snapshot_df):\n",
    "    snapshot_ = pd.read_pickle(snapshot_df, compression='gzip')\n",
    "    hbt = HftBacktest(X,\n",
    "                      tick_size=0.1,\n",
    "                      lot_size=0.001,\n",
    "                      maker_fee=-0.00005,\n",
    "                      taker_fee=0.0007,\n",
    "                      order_latency=FeedLatency(1),\n",
    "                      asset_type=Linear,\n",
    "                      snapshot=snapshot_)\n",
    "    stat = Stat(hbt)\n",
    "    \n",
    "    while hbt.run:\n",
    "        # Running interval in microseconds\n",
    "        if not hbt.elapse(0.1 * 1e6):\n",
    "            return False\n",
    "        # Clear cancelled, filled or expired orders.\n",
    "        hbt.clear_inactive_orders()\n",
    "        \n",
    "        binNum = 100\n",
    "        \n",
    "        \n",
    "        ## Get market depth\n",
    "        depth_market = 1001\n",
    "        bid = []\n",
    "        ask = []\n",
    "        i = 0\n",
    "        for tick_price in range(hbt.best_ask_tick, hbt.high_ask_tick + 1):\n",
    "            if tick_price in hbt.ask_depth:\n",
    "                ask.append([tick_price * hbt.tick_size, hbt.ask_depth[tick_price]])\n",
    "                i += 1\n",
    "                if i == depth_market:\n",
    "                    break\n",
    "        i = 0\n",
    "        for tick_price in range(hbt.best_bid_tick, hbt.low_bid_tick - 1, -1):\n",
    "            if tick_price in hbt.bid_depth:\n",
    "                bid.append([tick_price * hbt.tick_size, hbt.bid_depth[tick_price]])\n",
    "                i += 1\n",
    "                if i == depth_market:\n",
    "                    break\n",
    "\n",
    "                    \n",
    "        ## Define Parameter\n",
    "        # max_position = 100000\n",
    "        # order_interval = hbt.tick_size * 10\n",
    "        # grid_num = 20\n",
    "        # half_spread = hbt.tick_size * 20\n",
    "        # depth = 0.05\n",
    "        # lineNumber = 5\n",
    "        # binNum=50 \n",
    "        # skew = 1\n",
    "        \n",
    "                           \n",
    "        \n",
    "        \n",
    "        ## Calculate alpha\n",
    "        mid_price = (hbt.best_bid + hbt.best_ask) / 2.0 \n",
    "#         buy = 0.0\n",
    "#         sell = 0.0       \n",
    "#         bid_arr = np.array(bid)\n",
    "#         ask_arr = np.array(ask)\n",
    "#         for i in range(bid_arr.shape[0]):\n",
    "#             if bid_arr[i, 0] > mid_price * (1 - depth):\n",
    "#                 buy += bid_arr[i, 1]\n",
    "\n",
    "#         for i in range(ask_arr.shape[0]):\n",
    "#             if ask_arr[i, 0] > mid_price * (1 + depth):\n",
    "#                 sell += ask_arr[i, 1]\n",
    "#         alpha = buy - sell\n",
    "#         if alpha > 0:\n",
    "#             skew = 1\n",
    "#         else:\n",
    "#             skew = -1\n",
    "\n",
    "        reservation_price = mid_price + skew * hbt.tick_size * hbt.position \n",
    "        # print(reservation_price)\n",
    "        # print(skew * hbt.position * hbt.tick_size)\n",
    "        # return True\n",
    "        \n",
    "        \n",
    "        \n",
    "        limitPercent = (reservation_price + half_spread) / reservation_price - 1\n",
    "        bid, ask = limitExtractDepth(bid,ask,limitPercent,reservation_price)\n",
    "        supportLevel, resistanceLevel = getSupportResistance(bid, ask, limitPercent, lineNumber)   \n",
    "        order_qty = 0.1 # np.round(notional_order_qty / mid_price / hbt.lot_size) * hbt.lot_size\n",
    "        last_order_id = -1\n",
    "        \n",
    "        # Create a new grid for buy orders.\n",
    "        new_bid_orders = Dict.empty(np.int64, np.float64)\n",
    "        if hbt.position < max_position: # hbt.position * mid_price < max_notional_position\n",
    "            p = hbt.position\n",
    "            \n",
    "            ##Support \n",
    "            \n",
    "            for bid in supportLevel:                \n",
    "                bid_order_price = bid[0] # supportLevel = [[0.01254, 11310.9], [0.0125, 3453.6]....]\n",
    "                bid_order_tick = round(bid_order_price / hbt.tick_size)\n",
    "                # Do not post buy orders above the best bid and below grid range.\n",
    "                if bid_order_tick > hbt.best_bid_tick:\n",
    "                    continue\n",
    "                p += order_qty\n",
    "                # Do not post buy orders that can exceed the maximum position.\n",
    "                if p >= max_position:\n",
    "                    continue\n",
    "                # order price in tick is used as order id.\n",
    "                new_bid_orders[bid_order_tick] = bid_order_price\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for order in hbt.orders.values():\n",
    "            # Cancel if an order is not in the new grid.\n",
    "            if order.side == BUY and order.cancellable and order.order_id not in new_bid_orders:\n",
    "                hbt.cancel(order.order_id)\n",
    "                last_order_id = order.order_id\n",
    "        for order_id, order_price in new_bid_orders.items():\n",
    "            # Post an order if it doesn't exist.\n",
    "            if order_id not in hbt.orders:\n",
    "                hbt.submit_buy_order(order_id, order_price, order_qty, GTX)\n",
    "                last_order_id = order_id\n",
    "                # print(\"test bid\")\n",
    "        \n",
    "        # Create a new grid for sell orders.\n",
    "        new_ask_orders = Dict.empty(np.int64, np.float64)\n",
    "        if hbt.position > -max_position: # hbt.position * mid_price > -max_notional_position\n",
    "            p = hbt.position\n",
    "            \n",
    "            ## RESISTANCE \n",
    "            for ask in resistanceLevel:  \n",
    "                ask_order_price = ask[0] # resistanceLevel = [[0.01254, 11310.9], [0.0125, 3453.6]....]\n",
    "                ask_order_tick = round(ask_order_price / hbt.tick_size)\n",
    "                # Do not post sell orders below the best ask and above grid range\n",
    "                if ask_order_tick < hbt.best_ask_tick:\n",
    "                    continue\n",
    "                p += order_qty\n",
    "                # Do not post buy orders that can exceed the maximum position.\n",
    "                if p <= -max_position:\n",
    "                    continue\n",
    "                # order price in tick is used as order id.\n",
    "                new_ask_orders[ask_order_tick] = ask_order_price\n",
    "                # print(\"check\")\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "        for order in hbt.orders.values():\n",
    "            # Cancel if an order is not in the new grid.\n",
    "            if order.side == SELL and order.cancellable and order.order_id not in new_ask_orders:\n",
    "                hbt.cancel(order.order_id)\n",
    "                last_order_id = order.order_id\n",
    "        for order_id, order_price in new_ask_orders.items():\n",
    "            # Post an order if it doesn't exist.\n",
    "            if order_id not in hbt.orders:\n",
    "                hbt.submit_sell_order(order_id, order_price, order_qty, GTX)\n",
    "                # print(\"check 2\")\n",
    "                last_order_id = order_id\n",
    "                # print(\"test ask\")\n",
    "        \n",
    "        # Elapse a process time\n",
    "        if not hbt.elapse(.05 * 1e6):\n",
    "            return False\n",
    "        \n",
    "        # All order requests are considered to be requested at the same time.\n",
    "        # Wait until one of the order responses is received.\n",
    "        if last_order_id >= 0:\n",
    "            if not hbt.wait_order_response(last_order_id):\n",
    "                return False\n",
    "            \n",
    "        stat.recorder.record(hbt)\n",
    "\n",
    "    return stat.equity(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e51b8810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Backtest:\n",
    "    def __init__(self, snapshot_df=None, half_spread=None, lineNumber=None, skew=None):\n",
    "        #order_interval, grid_num, half_spread, lineNumber, binNum, skew\n",
    "        self.snapshot_df = snapshot_df\n",
    "        self.half_spread = half_spread\n",
    "        self.lineNumber = lineNumber\n",
    "        self.skew = skew\n",
    "        \n",
    "    def set_params(self, half_spread, lineNumber, skew):\n",
    "        self.half_spread = half_spread\n",
    "        self.lineNumber = lineNumber\n",
    "        self.skew = skew\n",
    "        return self\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return { 'snapshot_df': self.snapshot_df, \n",
    "                'half_spread': self.half_spread, \n",
    "                'lineNumber': self.lineNumber, \n",
    "                'skew': self.skew }\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        equity = predict_njit(self.half_spread, \n",
    "                              self.lineNumber, self.skew, X, self.snapshot_df )\n",
    "        return equity\n",
    "    \n",
    "    def score(self, X):\n",
    "        equity = self.predict(X)\n",
    "        returns = (equity.diff() / 1000).fillna(0)\n",
    "\n",
    "        return np.divide(returns.mean(), returns.std()) if (returns.std()) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d527a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'half_spread': stats.uniform(1, 200),\n",
    "    'lineNumber': stats.uniform(1, 10),\n",
    "    'skew': stats.uniform(-5.0, 5)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(Backtest('CollectData/data/btcusdt_20230227.snapshot.pkl'),\n",
    "                            cv=[(np.arange(len(train)), np.arange(len(validate)))],\n",
    "                            param_distributions=param_dist,\n",
    "                            verbose=1,\n",
    "                            n_iter=1)\n",
    "\n",
    "# param_grid = {\n",
    "#     'half_spread': range(1, 201),\n",
    "#     'lineNumber': range(1, 11),\n",
    "#     'skew': range(-5, 6)\n",
    "# }\n",
    "\n",
    "# search = GridSearchCV(Backtest('CollectData/data/btcusdt_20230227.snapshot.pkl'),\n",
    "#                       cv=[(np.arange(len(train)), np.arange(len(validate)))],\n",
    "#                       param_grid=param_grid,\n",
    "#                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46e70445",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Temp\\ipykernel_15876\\2354703380.py\", line 30, in score\n",
      "    equity = self.predict(X)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Temp\\ipykernel_15876\\2354703380.py\", line 25, in predict\n",
      "    equity = predict_njit(self.half_spread,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Temp\\ipykernel_15876\\1064291547.py\", line 3, in predict_njit\n",
      "    hbt = HftBacktest(X,\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"D:\\Git_Data\\LuanAnTN\\AlgorithmicTrading\\hftbacktest\\__init__.py\", line 107, in HftBacktest\n",
      "    exch_to_local_orders = OrderBus()\n",
      "                           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\experimental\\jitclass\\base.py\", line 124, in __call__\n",
      "    return cls._ctor(*bind.args[1:], **bind.kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\dispatcher.py\", line 487, in _compile_for_args\n",
      "    raise e\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\dispatcher.py\", line 420, in _compile_for_args\n",
      "    return_val = self.compile(tuple(argtypes))\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\dispatcher.py\", line 965, in compile\n",
      "    cres = self._compiler.compile(args, return_type)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\dispatcher.py\", line 125, in compile\n",
      "    status, retval = self._compile_cached(args, return_type)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\dispatcher.py\", line 139, in _compile_cached\n",
      "    retval = self._compile_core(args, return_type)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\dispatcher.py\", line 152, in _compile_core\n",
      "    cres = compiler.compile_extra(self.targetdescr.typing_context,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\compiler.py\", line 742, in compile_extra\n",
      "    return pipeline.compile_extra(func)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\compiler.py\", line 460, in compile_extra\n",
      "    return self._compile_bytecode()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\compiler.py\", line 528, in _compile_bytecode\n",
      "    return self._compile_core()\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\compiler.py\", line 507, in _compile_core\n",
      "    raise e\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\compiler.py\", line 494, in _compile_core\n",
      "    pm.run(self.state)\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\compiler_machinery.py\", line 368, in run\n",
      "    raise patched_exception\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\compiler_machinery.py\", line 356, in run\n",
      "    self._runPass(idx, pass_inst, state)\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\compiler_lock.py\", line 35, in _acquire_compile_lock\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\compiler_machinery.py\", line 311, in _runPass\n",
      "    mutated |= check(pss.run_pass, internal_state)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\compiler_machinery.py\", line 273, in check\n",
      "    mangled = func(compiler_state)\n",
      "              ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\typed_passes.py\", line 468, in run_pass\n",
      "    lower.create_cpython_wrapper(flags.release_gil)\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\lowering.py\", line 297, in create_cpython_wrapper\n",
      "    self.context.create_cpython_wrapper(self.library, self.fndesc,\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\cpu.py\", line 187, in create_cpython_wrapper\n",
      "    builder.build()\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\callwrapper.py\", line 122, in build\n",
      "    self.build_wrapper(api, builder, closure, args, kws)\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\callwrapper.py\", line 190, in build_wrapper\n",
      "    obj = api.from_native_return(retty, retval, env_manager)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\pythonapi.py\", line 1420, in from_native_return\n",
      "    out = self.from_native_value(typ, val, env_manager)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\pythonapi.py\", line 1434, in from_native_value\n",
      "    return impl(typ, val, c)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\experimental\\jitclass\\boxing.py\", line 191, in _box_class_instance\n",
      "    box_subclassed = _specialize_box(typ)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\experimental\\jitclass\\boxing.py\", line 154, in _specialize_box\n",
      "    raise TypeError(f\"Method '{name}' is not supported.\")\n",
      "TypeError: Failed in nopython mode pipeline (step: native lowering)\n",
      "Method '__delitem__' is not supported.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\coppy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=[(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 1...\n",
       "                   estimator=&lt;__main__.Backtest object at 0x00000174678E6390&gt;,\n",
       "                   n_iter=1,\n",
       "                   param_distributions={&#x27;half_spread&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000174678E6350&gt;,\n",
       "                                        &#x27;lineNumber&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000174674530D0&gt;,\n",
       "                                        &#x27;skew&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001746795AAD0&gt;},\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=[(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 1...\n",
       "                   estimator=&lt;__main__.Backtest object at 0x00000174678E6390&gt;,\n",
       "                   n_iter=1,\n",
       "                   param_distributions={&#x27;half_spread&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000174678E6350&gt;,\n",
       "                                        &#x27;lineNumber&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000174674530D0&gt;,\n",
       "                                        &#x27;skew&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001746795AAD0&gt;},\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Backtest</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.Backtest object at 0x00000174678E6390&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Backtest</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.Backtest object at 0x00000174678E6390&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=[(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 1...\n",
       "                   estimator=<__main__.Backtest object at 0x00000174678E6390>,\n",
       "                   n_iter=1,\n",
       "                   param_distributions={'half_spread': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000174678E6350>,\n",
       "                                        'lineNumber': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000174674530D0>,\n",
       "                                        'skew': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001746795AAD0>},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import warnings\n",
    "\n",
    "# # Ignore all warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "search.fit(train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f66b2eff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'half_spread': 3.035813512141238,\n",
       " 'lineNumber': 1.9129822681697775,\n",
       " 'skew': -4.685905767032752}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "061f1ca0-0a8c-4b08-b760-c275697f4417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open('parameters.txt', 'w') as f:\n",
    "#     f.write(str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8dc5fb-c22f-457d-8634-0d247dd548f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb823a-e4ac-44d5-b8a0-44b5590ff984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
